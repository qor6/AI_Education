{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"opencv.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO0mXz1fb3x0fOh7Nmr1wo0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"pBWyZgxyXnHB"},"source":["# img show\n","import os\n","import cv2\n","\n","path = './data/' #데이터 있는 곳 경로\n","fname = os.path.join(path, \"lena.jpg\")\n","\n","original = cv2.imread(fname, cv2.IMREAD_COLOR) #RGB로\n","gray = cv2.imread(fname, cv2.IMREAD_GRAYSCALE) #흑백으로\n","unchange = cv2.imread(fname, cv2.IMREAD_UNCHANGED) #변경x\n","\n","cv2.imshow('Origianl',original)\n","cv2.imshow('Gray',gray)\n","cv2.imshow('unchange',unchange)\n","\n","cv2.waitKey(0) # waitKey(time)는 지정한 시간(time, ms)마다 프레임 재생\n","cv2.destoryAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jupCKA8JXn7U"},"source":["# img save\n","import os\n","import sys\n","import cv2\n","\n","path = './data/' #데이터 있는 곳 경로\n","fname = os.path.join(path, \"lena.jpg\")\n","\n","img = cv2.imread(fname, cv2.IMREAD_COLOR)\n","\n","if img is None:\n","    print('Image load failed')\n","    sys.exit()\n","    \n","cv2.imshow('image', img)\n","\n","k = cv2.waitKey(0) & 0xFF\n","if k == 27:\n","    cv2.destroyAllWindow()\n","elif k == ord('s'):\n","    cv2.imwrite('lenagray.png', img)\n","    cv2.destroyAllWindow()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wUASN8dJXxCk"},"source":["# matplotUsage\n","import cv2\n","import os\n","\n","from matplotlib import pyplot as plt\n","\n","path = './data/'\n","fname = os.path.join(path, \"starry_night.jpg\")\n","\n","img = cv2.imread(fname, cv2.IMREAD_COLOR)\n","\n","plt.imshow(img)\n","plt.xticks([])\n","plt.yticks([])\n","plt.show\n","\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_56UjWZBXzLs"},"source":["# matplotUsage_modify\n","import cv2\n","import os\n","\n","from matplotlib import pyplot as plt\n","\n","path = './data/'\n","fname = os.path.join(path, \"starry_night.jpg\")\n","\n","img = cv2.imread(fname, cv2.IMREAD_COLOR)\n","\n","b,g,r = cv2.split(img)\n","img2=cv2.merge([r,g,b]) #list로\n","\n","plt.imshow(img2)\n","#plt.imshow(b) # 흑백으로 나옴 0~255(완벽 파랑)\n","plt.xticks([])\n","plt.yticks([])\n","plt.show\n","\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G4zHsc9XX1T0"},"source":["# capture video from camera 카메라로부터 영상 재생\n","import cv2\n","\n","# cap이 정상적으로 open이 되었는지 확인하기 위해서 cap.isOpen()으로 확인 가능\n","cap = cv2.VideoCapture(0) #0은 카메라를 받음\n","print(cap.isOpened()) #정상적으로 열렸는지 print\n","\n","# cap.get(prodId) / cap.set(propId, value)을 통해서 속성 변경이 가능.\n","# 3은 width, 4는 heigh\n","print('width : {0}, height : {1}'.format(cap.get(3),cap.get(4)))\n","\n","# cap.set(3,320)\n","# cap.set(4,240)\n","while(True):\n","    # ret(boolean) = frame capture 결과\n","    # frame = capture한 frame\n","    ret, frame = cap.read()\n","    \n","    if (ret):\n","        # image를 grayscale로 convert함. 전환\n","        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        # gray = cv2.cvtColor(frame, 0)\n","        \n","        cv2.imshow('frame', gray)\n","        if cv2.waitKey(1) & 0xff == ord('q'): \n","            break\n","            \n","cap.release()\n","cv2.destroyAllWindows()        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ogos0thPX3I0"},"source":["# 동영상 계속 재생\n","import os\n","import numpy as np\n","import cv2 as cv\n","\n","path = './data/'\n","\n","fname = os.path.join(path, 'vtest.avi')\n","cap = cv.VideoCapture(fname)\n","# 33ms for a frame, framerate = 33\n","\n","# set on FPS\n","FPS = cap.get(cv.CAP_PROP_FPS)\n","print(FPS) #한장에 몇 ms\n","\n","framerate = round(1000/FPS) # 프레임  #round 반올림함수\n","\n","while cap.isOpened():\n","    frame_pos = cap.get(cv.CAP_PROP_POS_FRAMES)\n","    frame_count = cap.get(cv.CAP_PROP_FRAME_COUNT)\n","    print(\"%d/%d\" %(frame_pos, frame_count))\n","    \n","    #반복을 해주는 구간\n","    if (frame_pos == frame_count):\n","        cap.open(path+'vtest.avi')\n","    \n","    ret, frame = cap.read()\n","    cv.imshow(\"video frame\", frame)\n","    cv.imshow(\"inversed video frame\", ~frame) #영상 반전\n","    \n","    if cv.waitKey(framerate) > 0 : break\n","cap.release()\n","cv.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Woz6FwoUX4n9"},"source":["# 동영상 1회 재생 a frame per 1ms\n","import os\n","import numpy as np\n","import cv2 as cv\n","\n","path = './data/'\n","fname = os.path.join(path, 'vtest.avi')\n","cap = cv.VideoCapture(fname)\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    \n","    frame_pos = cap.get(cv.CAP_PROP_POS_FRAMES)\n","    frame_count = cap.get(cv.CAP_PROP_FRAME_COUNT)\n","    print(frame_pos, frame_count)\n","    \n","    # 만일 frame이 read correctly ret is True\n","    if not ret:\n","        print(\"Can't receive frame (stream end?). Exiting ...\")\n","        break\n","        \n","    #step1 : display Grayscale    \n","    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY) #흑백은 채널 1개\n","    cv.imshow('frame_gray',gray)\n","    \n","    #step2\n","    gray_ = cv.cvtColor(gray, cv.COLOR_GRAY2BGR) #RGB는 채널 3개\n","    merged = np.hstack((frame, gray_)) #붙이는 작업\n","    cv.imshow('Original + Gray frame', merged)\n","    \n","    #step3 : 라플라시안 필터 적용\n","    edge = cv.Laplacian(frame, -1)\n","    laplacian = np.hstack((frame, edge))\n","    cv.imshow('Laplacian filter', laplacian)\n","    \n","    if cv.waitKey(1) == ord('q'): #waitKey(100) 100은 0.1초 으로 하니깐 느려짐\n","        break\n","        \n","cap.release()\n","cv.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"441vb3WbX6E8"},"source":["!pip install pafy\n","!pip install youtube-dl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ijtzLtK_X71s"},"source":["import cv2\n","# 카메리 대신 youtube영상 대체\n","import pafy # pafy 패키지는 youtube의 메타 데이터를 수집/검색하거나 다운로드 해주는 패키지\n","# !pip install pafy\n","# !pip install youtube-dl\n","\n","#youtube 영상을 받기 위함 \n","url = 'https://www.youtube.com/watch?v=GUdnTGnm6Yk'\n","video = pafy.new(url)\n","print('title = ', video.title)\n","print('video.rating = ', video.rating)\n","print('video.duration = ', video.duration)\n","\n","best = video.getbest(preftype = 'mp4')\n","print('best.resolution', best.resolution)\n","\n","cap = cv2.VideoCapture(best.url)\n","#~여기 까지 youtube영상을 받기 위함\n","\n","#frame size 는 튜플로 받음, []는 list\n","frame_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n","              int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n","              int(cap.get(cv2.CAP_PROP_FPS)))\n","print('frame_size =',frame_size)\n","\n","# 코덱 설정하기\n"," # fourcc = cv2.VideoWriter_fourcc(*'DIVX') #('D', 'I', 'V', 'X')\n","fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","\n","out1 = cv2.VideoWriter('./data/record0.mp4', fourcc, 20.0,\n","                                (frame_size[0], frame_size[1]))\n","out2 = cv2.VideoWriter('./data/record1.mp4', fourcc, 20.0,\n","                                (frame_size[0], frame_size[1]),isColor=False)\n","while True:\n","    retval, frame = cap.read()\n","    if not retval:\n","        break\n","    out1.write(frame)\n","    \n","    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n","    \n","    out2.write(gray)\n","    \n","    cv2.imshow('frame', frame)\n","    cv2.imshow('gray', gray)\n","    \n","    if cv2.waitKey(1) == ord('q'):\n","        break\n","cap.release()\n","out1.release()\n","out2.release()\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m-3vg1qVX9Y0"},"source":["pip install opencv-contrib-python"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xohwSUzwX_BG"},"source":["import os\n","import cv2\n","import timeit\n","\n","url = 'https://www.youtube.com/watch?v=GUdnTGnm6Yk'\n","video = pafy.new(url)\n","print('title = ', video.title)\n","print('video.rating = ', video.rating)\n","print('video.duration = ', video.duration)\n","\n","best = video.getbest(preftype = 'mp4')\n","print('best.resolution', best.resolution)\n","\n","cap = cv2.VideoCapture(best.url)\n","'''\n","path = './data/'\n","fname = os.path.join(path, 'vtest.avi')\n","cap = cv2.VideoCapture(fname)\n","'''\n","\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","delay = int(1000/fps)\n","\n","# fgbg1 = cv2.bgsegm.createBackgroundSubtractorMDG()\n","# fgbg2 = cv2.createBackgroundSubtractorMDG2()\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","#     fgmask1 = fgbg1.apply(frame)\n","    fgmask2 = fgbg2.apply(frame)\n","    cv2.imshow('frame', frame)\n","#     cv2.imshow('bgsub-MOG', fgmask1)\n","    cv2.imshow('bgsub-MOG2', fgmask2)\n","    \n","    if cv2.waitKey(delay) & 0xff == ord('q'):\n","        break\n","cap.release()\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f2Zuh8zGYAiE"},"source":["!pip install opencv-contrib-python"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ykcbN8tbYCXl"},"source":["import os,sys\n","import cv2\n","\n","path = './data/'\n","fname = os.path.join(path, \"opencv-logo.png\")\n","\n","img = cv2.imread(fname)\n","if img is None:\n","    print('image load failed')\n","    sys.exit()\n","    \n","bgr = cv2.imread(fname, cv2.IMREAD_COLOR)\n","bgra = cv2.imread(fname, cv2.IMREAD_UNCHANGED)\n","\n","print(\"default\", img.shape, \"color\", bgr.shape, \"unchanged\", bgra.shape)\n","\n","cv2.imshow('bgr', bgr)\n","cv2.imshow('bgra', bgra)\n","cv2.imshow('alpha', bgra[:,:,3]) # 알파(투명도) 채널만 표시\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xxMcOtxDYDyt"},"source":["import os,sys\n","import cv2\n","import numpy as np\n","\n","path = './data/'\n","fname = os.path.join(path, \"home.jpg\") # RGB 채널 잇는 파일임\n","\n","img = cv2.imread(fname)\n","if img is None:\n","    print('image load failed')\n","    sys.exit()\n","    \n","img2 = img.astype(np.uint16)\n","b,g,r = cv2.split(img2)\n","gray1 = ((b+g+r)/3).astype(np.uint8)\n","gray2 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","gray3 = g.astype(np.uint8)\n","gray4 = b.astype(np.uint8)\n","gray5 = r.astype(np.uint8)\n","\n","cv2.imshow('original', img)\n","cv2.imshow('gray1', gray1)\n","cv2.imshow('gray2', gray2)\n","cv2.imshow('gray3', gray3)\n","cv2.imshow('gray4', gray4)\n","cv2.imshow('gray5', gray5)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WjrfVuKJYFPN"},"source":["import os,sys\n","import cv2\n","import numpy as np\n","\n","path = './data2/'\n","fname = os.path.join(path, \"sunset.jpg\") \n","\n","img = cv2.imread(fname)\n","if img is None:\n","    print('image load failed')\n","    sys.exit()\n","    \n","# 선택 영역 표시\n","x,y,w,h = cv2.selectROI(\"image\", img, False) #x,y는 왼쪽 젤 위 좌표값 \n","\n","if w and h:\n","    roi = img[y:y+h, x:x+h] #y수직, x수평\n","    cv2.imshow('cropped', roi)\n","    cv2.moveWindow('cropped', 0,0)\n","    # cv2.imwrite('./cropped2.jpg', roi)\n","    \n","\n","\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6O90e4bqYF28"},"source":["#이미지 합치기 \n","import os,sys\n","import cv2\n","import numpy as np\n","\n","path = './data/'\n","img1 = cv2.imread(os.path.join(path, \"flower1.jpg\"))\n","img2 = cv2.imread(os.path.join(path, \"flower2.jpg\"))\n","\n","win_name = 'alpha'\n","trackbar_name = 'fade'\n","def onChange(x):\n","    alpha = x/100\n","    dst = cv2.addWeighted(img1, 1-alpha, img2, alpha, 0)\n","    cv2.imshow(win_name, dst)\n","\n","cv2.imshow(win_name, img1)\n","cv2.createTrackbar(trackbar_name, win_name, 0, 100, onChange)\n","cv2.waitKey()\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gdhreVH5YHPl"},"source":["#이미지 합치기 (다른사진으로)\n","import os,sys\n","import cv2\n","import numpy as np\n","\n","path = './data2/'\n","img1 = cv2.imread(os.path.join(path, \"man_face.jpg\"))\n","img2 = cv2.imread(os.path.join(path, \"lion_face.jpg\"))\n","\n","win_name = 'alpha'\n","trackbar_name = 'fade'\n","def onChange(x):\n","    alpha = x/100\n","    dst = cv2.addWeighted(img1, 1-alpha, img2, alpha, 0)\n","    cv2.imshow(win_name, dst)\n","\n","cv2.imshow(win_name, img1)\n","cv2.createTrackbar(trackbar_name, win_name, 0, 100, onChange)\n","cv2.waitKey()\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DXB6qE0sYJOV"},"source":["# 이미지 합치기 and or xor not\n","import numpy as np, cv2\n","import matplotlib.pylab as plt\n","\n","# path = './data2/'\n","# img1 = cv2.imread(os.path.join(path, \"man_face.jpg\"))\n","# img2 = cv2.imread(os.path.join(path, \"lion_face.jpg\"))\n","img1 = np.zeros((200,400), dtype=np.uint8)\n","img2 = np.zeros((200,400), dtype=np.uint8)\n","img1[:, : 200] = 255   #왼 :255(흰)\n","img2[100:200, :] = 255 #위 :0(검)\n","\n","bitAnd = cv2.bitwise_and(img1,img2)\n","bitOr = cv2.bitwise_or(img1,img2)\n","bitXor = cv2.bitwise_xor(img1,img2)\n","bitNot = cv2.bitwise_not(img1)\n","\n","def onChange(x):\n","    alpha = x/100\n","    dst = cv2.addWeighted(img1, 1-alpha, img2, alpha, 0)\n","    cv2.imshow(win_name, dst)\n","\n","cv2.imshow(win_name, img1)\n","cv2.createTrackbar(trackbar_name, win_name, 0, 100, onChange)\n","cv2.waitKey()\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PrQBIJjuYiBW"},"source":["# New Section"]},{"cell_type":"code","metadata":{"id":"P1Cx7nogYK6m"},"source":["import os, sys\n","import numpy as np, cv2\n","path = './data2/'\n","\n","img1 = cv2.imread(os.path.join(path, \"robot_arm1.jpg\"))\n","img2 = cv2.imread(os.path.join(path, \"robot_arm2.jpg\"))\n","\n","img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n","img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n","\n","diff = cv2.absdiff(img1_gray, img2_gray)\n","\n","ret, diff = cv2.threshold(diff, 1, 255, cv2.THRESH_BINARY)\n","diff_red = cv2.cvtColor(diff, cv2.COLOR_GRAY2BGR)\n","\n","diff_red[:,:,2] = 0\n","spot = cv2.bitwise_xor(img2, diff_red)\n","\n","cv2.imshow('img1', img1)\n","cv2.imshow('img2', img2)\n","cv2.imshow('diff', diff)\n","cv2.imshow('spot', spot)\n","cv2.waitKey()\n","cv2.destoryAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rphb56BFYMp9"},"source":["import os, sys\n","import cv2\n","import numpy as np\n","import matplotlib.pylab as plt\n","\n","path = './data2/'\n","\n","img1 = cv2.imread(os.path.join(path, \"man_chromakey.jpg\"))\n","img2 = cv2.imread(os.path.join(path, \"street.jpg\"))\n","\n","height1, width1 = img1.shape[:2]\n","height2, width2 = img2.shape[:2]\n","\n","x=(width2 - width1)//2\n","y=height2 - height1\n","w=x + width1\n","h=y + height1\n","\n","chromakey = img1[:10, :10, :]\n","offset=20 #실험적인 값\n","\n","hsv_chroma = cv2.cvtColor(chromakey, cv2.COLOR_BGR2HSV)\n","hsv_img = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)\n","\n","chroma_h = hsv_chroma[:,:,0]\n","lower = np.array([chroma_h.min()-offset, 100, 100])\n","upper = np.array([chroma_h.max()+offset, 255, 255])\n","\n","mask = cv2.inRange(hsv_img, lower, upper)\n","mask_inv = cv2.bitwise_not(mask)\n","roi = img2[y:h, x:w]\n","fg = cv2.bitwise_and(img1, img1, mask=mask_inv)\n","bg = cv2.bitwise_and(roi, roi, mask=mask)\n","img2[y:h, x:w] = fg + bg\n","\n","cv2.imshow('fg', fg)\n","cv2.imshow('bg', bg)\n","cv2.imshow('chromakey', img1)\n","cv2.imshow('added', img2)\n","cv2.waitKey()\n","cv2.destoryAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mZoVY-pEYOWe"},"source":["import os, sys\n","import cv2\n","import numpy as np\n","import matplotlib.pylab as plt\n","\n","path = './data2/'\n","\n","img1 = cv2.imread(os.path.join(path, \"drawing.jpg\"))\n","img2 = cv2.imread(os.path.join(path, \"my_hand.jpg\"))\n","\n","mask = np.full_like(img1, 255)\n","\n","height, width = img2.shape[:2]\n","center = (width//2, height//2)\n","\n","normal = cv2.seamlessClone(img1, img2, mask,center, cv2.NORMAL_CLONE)\n","mixed = cv2.seamlessClone(img1, img2, mask,center, cv2.MIXED_CLONE)\n","\n","cv2.imshow('fg', img1)\n","cv2.imshow('bg', img2)\n","cv2.imshow('mask', mask)\n","cv2.imshow('normal', normal)\n","cv2.imshow('mixed', mixed)\n","cv2.waitKey()\n","cv2.destoryAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mQ_t0Wl7hBGr"},"source":[""]},{"cell_type":"code","metadata":{"id":"OvRiosNvhAYt"},"source":["import os, sys\n","import cv2\n","import numpy as np\n","import matplotlib.pylab as plt\n","\n","path = './data2/'\n","img = cv2.imread(os.path.join(path, \"gray_gradient.jpg\"), cv2.IMREAD_GRAYSCALE)\n","\n","thresh_np = np.zeros_like(img)\n","thresh_np[img > 127] = 255\n","\n","ret, thresh_cv = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n","print(ret) # 127.0\n","\n","imgs = {'origianl' : img, 'numpy API' : thresh_np, 'cv2.threshold' : thresh_cv}\n","for i, (key, value) in enumerate(imgs.items()):\n","    plt.subplot(1, 3, i+1)\n","    plt.title(key)\n","    plt.imshow(value, cmap='gray')\n","    plt.xticks([]); plt.yticks([])\n","    \n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XIjfk5B9hD1V"},"source":["import os, sys\n","import cv2\n","import numpy as np\n","import matplotlib.pylab as plt\n","path = './data2/'\n","img = cv2.imread(os.path.join(path, \"sudoku.png\"), cv2.IMREAD_GRAYSCALE)\n","\n","blk_size = 9\n","c = 5\n","\n","ret, th1 = cv2.threshold(img, 0,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n","\n","th2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY, blk_size, c)\n","th3 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY, blk_size, c)\n","\n","imgs = {'Origianl' : img, 'Global-Otsu:%d' %ret:th1, \\\n","       'Adapted-Mean':th2, 'Adapted-Gaussian':th3}\n","for i, (k, v) in enumerate(imgs.items()):\n","    plt.subplot(2,2,i+1)\n","    plt.title(k)\n","    plt.imshow(v,'gray')\n","    plt.xticks([]), plt.yticks([])\n","plt.show"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ru1Nz5vBhGTG"},"source":["import os, sys\n","import cv2\n","import numpy as np\n","import matplotlib.pylab as plt\n","path = './data2/'\n","img = cv2.imread(os.path.join(path, \"sudoku.png\"), cv2.IMREAD_GRAYSCALE)\n","\n","blk_size = 155\n","c = 5\n","\n","ret, th1 = cv2.threshold(img, 0,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n","\n","th2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY, blk_size, c)\n","th3 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY, blk_size, c)\n","\n","imgs = {'Origianl' : img, 'Global-Otsu:%d' %ret:th1, \n","       'Adapted-Mean':th2, 'Adapted-Gaussian':th3}\n","for i, (k, v) in enumerate(imgs.items()):\n","    plt.subplot(2,2,i+1)\n","    plt.title(k)\n","    plt.imshow(v,'gray')\n","    plt.xticks([]), plt.yticks([])\n","plt.show"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ULB_9uBEhICO"},"source":["import os, sys\n","import cv2\n","import numpy as np\n","import matplotlib.pylab as plt\n","path = './data2/'\n","img = cv2.imread(os.path.join(path, 'bright.jpg'))\n","img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n","\n","img_eq = img_yuv.copy()\n","img_eq[:,:,0] = cv2.equalizeHist(img_eq[:,:,0])\n","img_eq = cv2.cvtColor(img_eq, cv2.COLOR_YUV2BGR)\n","\n","img_clahe = img_yuv.copy()\n","clahe = cv2.createCLAHE(clipLimit = 3.0, tileGridSize=(8,8))\n","img_clahe[:,:,0] = clahe.apply(img_clahe[:,:,0])\n","img_clahe = cv2.cvtColor(img_clahe, cv2.COLOR_YUV2BGR)\n","\n","cv2.imshow('Before', img)\n","cv2.imshow('CLAHE', img_clahe)\n","cv2.imshow('equalizeHist', img_eq)\n","cv2.waitKey()\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PxGa4yShJVV"},"source":["import os, sys\n","import cv2\n","import numpy as np\n","import matplotlib.pylab as plt\n","\n","win_name = 'back_projection'\n","\n","path = './data2/'\n","img = cv2.imread(os.path.join(path, \"999.jpg\"))\n","hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n","draw = img.copy()\n","\n","def masking(bp, win_name):\n","    disc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n","    cv2.filter2D(bp,-1,disc,bp)\n","    _,mask = cv2.threshold(bp, 1, 255, cv2.THRESH_BINARY)\n","    result = cv2.bitwise_and(img, img, mask=mask)\n","    cv2.imshow(win_name, result)\n","\n","def backProject_manual(hist_roi):\n","    hist_img = cv2.calcHist([hsv_img],[0,1], None, [180,256], [0, 180, 0, 256])\n","    hist_rate = hist_roi/(hist_img+1)\n","    h,s,v = cv2.split(hsv_img)\n","    bp = hist_rate[h.ravel(), s.ravel()]\n","    bp = np.minimum(bp,1)\n","    bp = bp.reshape(hsv_img.shape[:2])\n","    cv2.normalize(bp,bp,0,255,cv2.NORM_MINMAX)\n","    bp = bp.astype(np.uint8)\n","    masking(bp,'result_manual')\n","    \n","def backProject_cv(hist_roi):\n","    bp = cv2.calcBackProject([hsv_img], [0,1], hist_roi,[0, 180, 0, 256], 1.)\n","    masking(bp,'result_cv')\n","\n","    \n","(x,y,w,h) = cv2.selectROI(win_name, img, False)\n","if w>0 and h>0:\n","    roi = draw[y:y+h, x:x+w]\n","    cv2.rectangle(draw, (x,y), (x+w,y+h), (0,0,255),2)\n","    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n","    hist_roi = cv2.calcHist([hsv_roi],[0,1],None,[180, 256],[0,180,0,256])\n","    backProject_manual(hist_roi)\n","    backProject_cv(hist_roi)\n","    \n","cv2.imshow(win_name, draw)\n","cv2.waitKey()\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]}]}